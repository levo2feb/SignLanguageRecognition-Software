# ğŸ¤Ÿ Sign Language Recognition System

A real-time sign language gesture recognition system that uses computer vision and machine learning to identify hand signs from a webcam feed. The system translates simple hand gestures into corresponding text, helping to bridge communication gaps for individuals with hearing or speech impairments.



## ğŸ“Œ Features

- Real-time hand gesture recognition using webcam
- Hand landmark detection using MediaPipe
- Custom dataset creation via webcam
- Trained machine learning model using Random Forest classifier
- Recognizes 3 signs: `Hi`, `Thumbs up`, and `Victory`



## ğŸ–¥ï¸ Technologies Used

- Python 3
- OpenCV â€“ Real-time image capture and processing
- MediaPipe â€“ Hand landmark detection
- scikit-learn â€“ Model training and classification
- Pickle â€“ Model persistence



## ğŸ—‚ï¸ Project Structure

â”œâ”€â”€ 1_collect_imgs.py # Collect images for each gesture class               <br>
â”œâ”€â”€ 2_create_dataset.py # Create dataset using MediaPipe                    <br>
â”œâ”€â”€ 3_train_classifier.py # Train classifier using extracted features       <br>
â”œâ”€â”€ 4_inference_classifier.py # Real-time prediction using webcam           <br> 
â”œâ”€â”€ cameracheck.py # Check if webcam is accessible                          <br>
â”œâ”€â”€ data/ # Folder containing gesture image data                            <br>
â”œâ”€â”€ data.pickle # Processed gesture landmark dataset                        <br>
â”œâ”€â”€ model.p # Trained classifier model                                      <br>




## ğŸš€ How to Run This Project

**1. ğŸ“¦ Install Dependencies -** Ensure you have Python 3 installed. Then install the required packages:
```bash
pip install opencv-python mediapipe scikit-learn matplotlib
```

**2. ğŸ¥ Check Camera Access -** Press q to exit the camera feed.
```bash
python cameracheck.py  
```


**3. ğŸ“¸ Collect Gesture Images -** Follow the prompts to press Q to start capturing for each gesture. This will save images in ./data/0, ./data/1, and ./data/2.
```bash
python 1_collect_imgs.py
```

**4. ğŸ§ª Generate Dataset -** This will generate data.pickle, containing the processed data and labels.
```bash
python 2_create_dataset.py
```


**5. ğŸ§  Train Classifier -** This will save the trained model in model.p. You'll also see the classification accuracy in the console.
```bash
python 3_train_classifier.py
```


**6. ğŸ–¥ï¸ Run Real-time Inference -** Use your webcam to predict gestures in real time:
```bash
python 4_inference_classifier.py
```

## ğŸ“ Notes
- You can modify the number of gesture classes or dataset size by editing 1_collect_imgs.py.
- Make sure you collect consistent and clear images for better accuracy.
- You can expand labels_dict in 4_inference_classifier.py to add new gestures.


## ğŸ’¡ Future Improvements
- Add more gesture classes
- Use a deep learning model for improved accuracy
- Add voice output for recognized gestures
- Build a mobile app version



